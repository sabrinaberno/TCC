{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6a7a02",
   "metadata": {},
   "source": [
    "Redes neurais de classifica√ß√£o geralmente t√™m uma camada final com uma fun√ß√£o sigmoid (para 1 sa√≠da) ou softmax (para m√∫ltiplas classes). Essa fun√ß√£o entrega uma probabilidade entre 0 e 1 para cada classe.\n",
    "\n",
    "Pe√ßa a sa√≠da raw da √∫ltima camada da rede, antes de tomar a decis√£o.\n",
    "Essa sa√≠da √© a probabilidade da classe positiva (euploide).\n",
    "Multiplique por 100 para transformar em porcentagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52ddfb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Padr√£o\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPadr√£o\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Aplica a transforma√ß√£o usando o scaler treinado\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# === 4. Faz a predi√ß√£o da classe (0 ou 1) ===\u001b[39;00m\n\u001b[0;32m     22\u001b[0m classes_preditas \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(X_scaled)\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1059\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1061\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1062\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Padr√£o\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# === 1. Carrega a planilha com os dados dos embri√µes ===\n",
    "df = pd.read_excel(\"PlanilhaNumerica.xlsx\")\n",
    "\n",
    "# === 2. Carrega o modelo e o scaler treinados ===\n",
    "modelo = joblib.load(\"melhor_modelo_mlp2.pkl\")\n",
    "scaler = joblib.load(\"scaler_mlp2.pkl\")\n",
    "\n",
    "# === 3. Prepara os dados ===\n",
    "X = df.drop(columns=[\"Ploidia\"])  # Remove a resposta real\n",
    "\n",
    "# Remove a coluna 'Padr√£o' se existir para evitar erro no scaler\n",
    "if 'Padr√£o' in X.columns:\n",
    "    X = X.drop(columns=['Padr√£o'])\n",
    "\n",
    "# Aplica a transforma√ß√£o usando o scaler treinado\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# === 4. Faz a predi√ß√£o da classe (0 ou 1) ===\n",
    "classes_preditas = modelo.predict(X_scaled)\n",
    "\n",
    "# === 5. Adiciona ao DataFrame original ===\n",
    "df[\"Classe_Prevista\"] = classes_preditas\n",
    "\n",
    "# === 6. Salva em nova planilha ===\n",
    "df.to_excel(\"Planilha_Com_Classificacao.xlsx\", index=False)\n",
    "\n",
    "print(\"‚úÖ Classifica√ß√µes salvas em 'Planilha_Com_Classificacao.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83bb460",
   "metadata": {},
   "source": [
    "## Pode testar isso aqui com a planilha nova de dados "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3ab7b",
   "metadata": {},
   "source": [
    "## Etapa 1: L√≥gica da Porcentagem\n",
    "\n",
    "Vamos usar as vari√°veis morfocin√©ticas e morfol√≥gicas da planilha. Para cada vari√°vel:\n",
    "\n",
    "- Se o valor do embri√£o estiver **na faixa favor√°vel**, ele ganha a **pontua√ß√£o cheia proporcional ao peso** daquela vari√°vel.\n",
    "- Se estiver **fora da faixa favor√°vel**, ganha **zero** (ou um valor intermedi√°rio, se quisermos refinar depois com mais precis√£o ou uma fun√ß√£o cont√≠nua).\n",
    "\n",
    "A **soma ponderada dos acertos** (vari√°veis que estiverem dentro da faixa favor√°vel) dar√° a **porcentagem estimada de euploidia**, variando de **0 a 100**.\n",
    "\n",
    "## Etapa 1: L√≥gica da Porcentagem\n",
    "\n",
    "Vamos usar as vari√°veis morfocin√©ticas e morfol√≥gicas da planilha. Para cada vari√°vel:\n",
    "\n",
    "- Se o valor do embri√£o estiver **na faixa favor√°vel**, ele ganha a **pontua√ß√£o cheia proporcional ao peso** daquela vari√°vel.\n",
    "- Se estiver **fora da faixa favor√°vel**, ganha **zero** (ou um valor intermedi√°rio, se quiser refinar depois com mais precis√£o ou uma fun√ß√£o cont√≠nua).\n",
    "\n",
    "A **soma ponderada dos acertos** (vari√°veis que estiverem dentro da faixa favor√°vel) dar√° a **porcentagem estimada de euploidia**, variando de **0 a 100**.\n",
    "\n",
    "---\n",
    "\n",
    "## Etapa 2: Pesos Normalizados (baseados na correla√ß√£o de Spearman ou evid√™ncia)\n",
    "\n",
    "Aqui est√£o os pesos que usaremos, totalizando 100%:\n",
    "\n",
    "| Vari√°vel     | Peso (%) |\n",
    "|--------------|----------|\n",
    "| Idade        | 28.25    |\n",
    "| t5           | 13.56    |\n",
    "| tB - tSB     | 15.82    |\n",
    "| cc3          | 15.82    |\n",
    "| Est√°gio      | 10.00    |\n",
    "| KIDScore     | 10.00    |\n",
    "| Morfologia   | 10.00    |\n",
    "| s2           | 5.00     |\n",
    "| cc2          | 5.00     |\n",
    "| t5 - t2      | 5.00     |\n",
    "| **Total**    | **100**  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ebd010",
   "metadata": {},
   "source": [
    "# Teste de classifica√ß√£o de ploidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f584464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conclu√≠do com sucesso!\n",
      "üìÑ Todas as classes: Planilha_Com_Classificacao.xlsx\n",
      "üìÑ Somente euploides: Planilha_Somente_Euploidia.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# 1. Carrega os dados\n",
    "df = pd.read_excel(\"PlanilhaNumerica.xlsx\")\n",
    "\n",
    "# 2. Carrega o modelo e o scaler treinados\n",
    "modelo = joblib.load(\"melhor_modelo_mlp_20250610_113659.pkl\")\n",
    "scaler = joblib.load(\"scaler_mlp_20250610_113659.pkl\")\n",
    "\n",
    "# 3. Prepara os dados\n",
    "X = df.drop(columns=[\"Ploidia\"], errors=\"ignore\")\n",
    "\n",
    "# 4. Preenche as colunas faltantes com 0 (ex: 'Padr√£o')\n",
    "colunas_treinadas = scaler.feature_names_in_\n",
    "for col in colunas_treinadas:\n",
    "    if col not in X.columns:\n",
    "        X[col] = 0  # Ou use np.nan e depois fillna com m√©dia, se preferir\n",
    "\n",
    "# 5. Garante a ordem correta das colunas\n",
    "X = X[colunas_treinadas]\n",
    "\n",
    "# 6. Aplica o scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# 7. Faz a predi√ß√£o\n",
    "classes_preditas = modelo.predict(X_scaled)\n",
    "\n",
    "# 8. Adiciona ao DataFrame original\n",
    "df[\"Classe_Prevista\"] = classes_preditas\n",
    "\n",
    "# 9. Salva planilha com todas as classifica√ß√µes\n",
    "df.to_excel(\"Planilha_Com_Classificacao.xlsx\", index=False)\n",
    "\n",
    "# 10. Salva planilha apenas com os embri√µes euploides\n",
    "df_euploides = df[df[\"Classe_Prevista\"] == 1]\n",
    "df_euploides.to_excel(\"Planilha_Somente_Euploidia.xlsx\", index=False)\n",
    "\n",
    "print(\"‚úÖ Conclu√≠do com sucesso!\")\n",
    "print(\"üìÑ Todas as classes: Planilha_Com_Classificacao.xlsx\")\n",
    "print(\"üìÑ Somente euploides: Planilha_Somente_Euploidia.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cefb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia (accuracy): 0.882\n",
      "Recall para Euploide (recall_1): 0.750\n",
      "Recall para Aneuploide (recall_0): 1.000\n",
      "AUC: 0.944\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === CARREGAR OS DADOS ===\n",
    "df_original = pd.read_excel(\"PlanilhaNumerica.xlsx\")\n",
    "X = df_original.drop(columns=[\"Ploidia\"], errors=\"ignore\")\n",
    "y = df_original[\"Ploidia\"]\n",
    "\n",
    "# === CARREGAR MODELO E SCALER SALVOS ===\n",
    "modelo = joblib.load(\"melhor_modelo_mlp_20250610_113659.pkl\")\n",
    "scaler = joblib.load(\"scaler_mlp_20250610_113659.pkl\")\n",
    "\n",
    "# === GARANTIR QUE AS COLUNAS EST√ÉO COMPLETAS ===\n",
    "colunas_treinadas = scaler.feature_names_in_\n",
    "\n",
    "for col in colunas_treinadas:\n",
    "    if col not in X.columns:\n",
    "        X[col] = 0  # ou np.nan e depois preencher com m√©dia, se preferir\n",
    "\n",
    "# === ORDENAR AS COLUNAS NA ORDEM CERTA ===\n",
    "X = X[colunas_treinadas]\n",
    "\n",
    "# === DIVIDIR OS DADOS ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === ESCALAR ===\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === FAZER PREVIS√ïES ===\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "y_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# === M√âTRICAS ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# === EXIBIR RESULTADOS ===\n",
    "print(f\"Acur√°cia (accuracy): {accuracy:.3f}\")\n",
    "print(f\"Recall para Euploide (recall_1): {recall_1:.3f}\")\n",
    "print(f\"Recall para Aneuploide (recall_0): {recall_0:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331195e",
   "metadata": {},
   "source": [
    "## parei em:\n",
    "- fazer ele classificar uma planilha, e retornar uma nova planilha somente com os euploides.\n",
    "- depois fazer a porcentagem de euploidia somente com essa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
