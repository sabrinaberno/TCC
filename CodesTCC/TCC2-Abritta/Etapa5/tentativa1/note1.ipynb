{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6a7a02",
   "metadata": {},
   "source": [
    "Redes neurais de classificação geralmente têm uma camada final com uma função sigmoid (para 1 saída) ou softmax (para múltiplas classes). Essa função entrega uma probabilidade entre 0 e 1 para cada classe.\n",
    "\n",
    "Peça a saída raw da última camada da rede, antes de tomar a decisão.\n",
    "Essa saída é a probabilidade da classe positiva (euploide).\n",
    "Multiplique por 100 para transformar em porcentagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52ddfb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Padrão\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPadrão\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Aplica a transformação usando o scaler treinado\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# === 4. Faz a predição da classe (0 ou 1) ===\u001b[39;00m\n\u001b[0;32m     22\u001b[0m classes_preditas \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(X_scaled)\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1059\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1061\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1062\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mc:\\Users\\maria.ferreira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Padrão\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# === 1. Carrega a planilha com os dados dos embriões ===\n",
    "df = pd.read_excel(\"PlanilhaNumerica.xlsx\")\n",
    "\n",
    "# === 2. Carrega o modelo e o scaler treinados ===\n",
    "modelo = joblib.load(\"melhor_modelo_mlp2.pkl\")\n",
    "scaler = joblib.load(\"scaler_mlp2.pkl\")\n",
    "\n",
    "# === 3. Prepara os dados ===\n",
    "X = df.drop(columns=[\"Ploidia\"])  # Remove a resposta real\n",
    "\n",
    "# Remove a coluna 'Padrão' se existir para evitar erro no scaler\n",
    "if 'Padrão' in X.columns:\n",
    "    X = X.drop(columns=['Padrão'])\n",
    "\n",
    "# Aplica a transformação usando o scaler treinado\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# === 4. Faz a predição da classe (0 ou 1) ===\n",
    "classes_preditas = modelo.predict(X_scaled)\n",
    "\n",
    "# === 5. Adiciona ao DataFrame original ===\n",
    "df[\"Classe_Prevista\"] = classes_preditas\n",
    "\n",
    "# === 6. Salva em nova planilha ===\n",
    "df.to_excel(\"Planilha_Com_Classificacao.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ Classificações salvas em 'Planilha_Com_Classificacao.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83bb460",
   "metadata": {},
   "source": [
    "## Pode testar isso aqui com a planilha nova de dados "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3ab7b",
   "metadata": {},
   "source": [
    "## Etapa 1: Lógica da Porcentagem\n",
    "\n",
    "Vamos usar as variáveis morfocinéticas e morfológicas da planilha. Para cada variável:\n",
    "\n",
    "- Se o valor do embrião estiver **na faixa favorável**, ele ganha a **pontuação cheia proporcional ao peso** daquela variável.\n",
    "- Se estiver **fora da faixa favorável**, ganha **zero** (ou um valor intermediário, se quisermos refinar depois com mais precisão ou uma função contínua).\n",
    "\n",
    "A **soma ponderada dos acertos** (variáveis que estiverem dentro da faixa favorável) dará a **porcentagem estimada de euploidia**, variando de **0 a 100**.\n",
    "\n",
    "## Etapa 1: Lógica da Porcentagem\n",
    "\n",
    "Vamos usar as variáveis morfocinéticas e morfológicas da planilha. Para cada variável:\n",
    "\n",
    "- Se o valor do embrião estiver **na faixa favorável**, ele ganha a **pontuação cheia proporcional ao peso** daquela variável.\n",
    "- Se estiver **fora da faixa favorável**, ganha **zero** (ou um valor intermediário, se quiser refinar depois com mais precisão ou uma função contínua).\n",
    "\n",
    "A **soma ponderada dos acertos** (variáveis que estiverem dentro da faixa favorável) dará a **porcentagem estimada de euploidia**, variando de **0 a 100**.\n",
    "\n",
    "---\n",
    "\n",
    "## Etapa 2: Pesos Normalizados (baseados na correlação de Spearman ou evidência)\n",
    "\n",
    "Aqui estão os pesos que usaremos, totalizando 100%:\n",
    "\n",
    "| Variável     | Peso (%) |\n",
    "|--------------|----------|\n",
    "| Idade        | 28.25    |\n",
    "| t5           | 13.56    |\n",
    "| tB - tSB     | 15.82    |\n",
    "| cc3          | 15.82    |\n",
    "| Estágio      | 10.00    |\n",
    "| KIDScore     | 10.00    |\n",
    "| Morfologia   | 10.00    |\n",
    "| s2           | 5.00     |\n",
    "| cc2          | 5.00     |\n",
    "| t5 - t2      | 5.00     |\n",
    "| **Total**    | **100**  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ebd010",
   "metadata": {},
   "source": [
    "# Teste de classificação de ploidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f584464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Concluído com sucesso!\n",
      "📄 Todas as classes: Planilha_Com_Classificacao.xlsx\n",
      "📄 Somente euploides: Planilha_Somente_Euploidia.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# 1. Carrega os dados\n",
    "df = pd.read_excel(\"PlanilhaNumerica.xlsx\")\n",
    "\n",
    "# 2. Carrega o modelo e o scaler treinados\n",
    "modelo = joblib.load(\"melhor_modelo_mlp_20250610_113659.pkl\")\n",
    "scaler = joblib.load(\"scaler_mlp_20250610_113659.pkl\")\n",
    "\n",
    "# 3. Prepara os dados\n",
    "X = df.drop(columns=[\"Ploidia\"], errors=\"ignore\")\n",
    "\n",
    "# 4. Preenche as colunas faltantes com 0 (ex: 'Padrão')\n",
    "colunas_treinadas = scaler.feature_names_in_\n",
    "for col in colunas_treinadas:\n",
    "    if col not in X.columns:\n",
    "        X[col] = 0  # Ou use np.nan e depois fillna com média, se preferir\n",
    "\n",
    "# 5. Garante a ordem correta das colunas\n",
    "X = X[colunas_treinadas]\n",
    "\n",
    "# 6. Aplica o scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# 7. Faz a predição\n",
    "classes_preditas = modelo.predict(X_scaled)\n",
    "\n",
    "# 8. Adiciona ao DataFrame original\n",
    "df[\"Classe_Prevista\"] = classes_preditas\n",
    "\n",
    "# 9. Salva planilha com todas as classificações\n",
    "df.to_excel(\"Planilha_Com_Classificacao.xlsx\", index=False)\n",
    "\n",
    "# 10. Salva planilha apenas com os embriões euploides\n",
    "df_euploides = df[df[\"Classe_Prevista\"] == 1]\n",
    "df_euploides.to_excel(\"Planilha_Somente_Euploidia.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ Concluído com sucesso!\")\n",
    "print(\"📄 Todas as classes: Planilha_Com_Classificacao.xlsx\")\n",
    "print(\"📄 Somente euploides: Planilha_Somente_Euploidia.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cefb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia (accuracy): 0.882\n",
      "Recall para Euploide (recall_1): 0.750\n",
      "Recall para Aneuploide (recall_0): 1.000\n",
      "AUC: 0.944\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === CARREGAR OS DADOS ===\n",
    "df_original = pd.read_excel(\"PlanilhaNumerica.xlsx\")\n",
    "X = df_original.drop(columns=[\"Ploidia\"], errors=\"ignore\")\n",
    "y = df_original[\"Ploidia\"]\n",
    "\n",
    "# === CARREGAR MODELO E SCALER SALVOS ===\n",
    "modelo = joblib.load(\"melhor_modelo_mlp_20250610_113659.pkl\")\n",
    "scaler = joblib.load(\"scaler_mlp_20250610_113659.pkl\")\n",
    "\n",
    "# === GARANTIR QUE AS COLUNAS ESTÃO COMPLETAS ===\n",
    "colunas_treinadas = scaler.feature_names_in_\n",
    "\n",
    "for col in colunas_treinadas:\n",
    "    if col not in X.columns:\n",
    "        X[col] = 0  # ou np.nan e depois preencher com média, se preferir\n",
    "\n",
    "# === ORDENAR AS COLUNAS NA ORDEM CERTA ===\n",
    "X = X[colunas_treinadas]\n",
    "\n",
    "# === DIVIDIR OS DADOS ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === ESCALAR ===\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === FAZER PREVISÕES ===\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "y_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# === MÉTRICAS ===\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# === EXIBIR RESULTADOS ===\n",
    "print(f\"Acurácia (accuracy): {accuracy:.3f}\")\n",
    "print(f\"Recall para Euploide (recall_1): {recall_1:.3f}\")\n",
    "print(f\"Recall para Aneuploide (recall_0): {recall_0:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331195e",
   "metadata": {},
   "source": [
    "## parei em:\n",
    "- fazer ele classificar uma planilha, e retornar uma nova planilha somente com os euploides.\n",
    "- depois fazer a porcentagem de euploidia somente com essa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
