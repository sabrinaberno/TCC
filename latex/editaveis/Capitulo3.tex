\chapter[Metodologia]{Metodologia}

\section{Classificação da Pesquisa}

\subsection{Natureza}

Em relação à natureza desta pesquisa, trata-se de uma pesquisa aplicada. Temos como objetivo principal gerar um conhecimento que possa ter um impacto direto e uma utilidade prática, ambos em contextos reais \cite{nascimento2016}. 

Com esta pesquisa, o desenvolvimento do modelo de IA tem a potencialidade de melhorar os sucessos dos tratamentos de FIV, fazendo o processo de seleção embrionária mais eficaz, menos invasivo e mais acessível a um maior número de pessoas.

\subsection{Método ou Abordagem Metodológica}

A metodologia ou abordagem metodológica dessa pesquisa é quantitativa \cite{nascimento2016}. Nosso foco é a análise dos dados numéricos referentes aos padrões morfocinéticos de embriões. Esses dados serão utilizados para o desenvolvimento da IA, que será capaz de prever a porcentagem de euploidia, auxiliando na seleção de embriões com maior possibilidade de saúde genética.

Escolher a abordagem quantitativa nos ajudará a atingir os objetivos desta pesquisa, permitindo explorar e validar os dados com precisão, oferecendo resultados objetivos. 

\subsection{Objetivos}

Quanto aos objetivos, o objetivo desta pesquisa é exploratório \cite{nascimento2016}. Este trabalho procura identificar e investigar padrões em dados morfocinéticos de embriões, usando o TLS, explorando a possibilidade de realizar essa predição juntamente com as tecnologias de IA.

Ao focar na concepção de um modelo que terá a capacidade de identificar padrões nos dados,exploraremos a relação entre esses dados e a importância de cada padrão para o resultado desejado, compreendendo os fatores que influenciam a saúde genética dos embriões, mas sem um conhecimento prévio estabelecido que explique completamente essas relações.

\subsection{Procedimentos De Pesquisa}

O procedimento adotado neste trabalho é experimental. Definimos este procedimento por causa do objetivo de investigar as relações entre as variáveis, o que é uma característica da pesquisa experimental \cite{nascimento2016}. Buscamos estabelecer uma relação de causa e efeito entre as características morfocinéticas dos embriões, mais especificamente a porcentagem de euploidia.

\section{Design da Pesquisa}

Esse estudo adotará o uso de IA para realizar a análise dos dados morfogenéticos dos embriões, desenvolvendo um modelo de predição baseado em machine learning. O modelo será treinado para identificar os padrões nos dados coletados pelo TLS, com foco em prever a porcentagem de euploidia, o que indica a saúde genética dos embriões.

Para desenvolver e testar o modelo, utilizaremos a linguagem de programação Python, aproveitando as bibliotecas disponíveis para a construção da IA. Quanto à validação do modelo, será elaborada uma fase experimental, na qual o modelo será testado com dados reais de embriões já classificados, a fim de compararmos e testarmos seu desempenho, refinando-o quando necessário.

Nesta pesquisa, buscaremos identificar e mapear os padrões em um campo que ainda está em desenvolvimento. A prática será testada em um ambiente controlado com dados obtidos pelo TLS, avaliando a efetividade do modelo com base na sua capacidade de prever, em porcentagem, a ploidia do embrião.

\section{Passos para o Desenvolvimento de um Algoritmo de Aprendizado de Máquina}

O desenvolvimento de sistemas baseados em aprendizado de máquina é um processo que envolve uma série de etapas bem definidas. Essas etapas vão desde a definição inicial do problema até a implementação e manutenção do sistema em um ambiente de produção. Segundo \citeonline{geron2017}, em \textit{Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow}, seguir uma abordagem estruturada permite que os desenvolvedores abordem os desafios de forma sistemática, garantindo não apenas a eficácia técnica do modelo, mas também sua aplicabilidade prática. O processo começa com a definição do problema e o entendimento do contexto geral. Depois, os dados são coletados, explorados para descobrir padrões e preparados para melhorar os resultados dos algoritmos. Em seguida, diferentes modelos são testados, e os melhores são ajustados para formar uma solução final. Essa solução é apresentada, implementada em produção e monitorada continuamente para garantir que funcione bem ao longo do tempo \cite{geron2017}.

\subsection{Definição do problema e análise do panorama geral}
A definição clara do problema e a análise do panorama geral são etapas essenciais para o sucesso de projetos de aprendizado de máquina, pois orienta todas as decisões subsequentes, desde a coleta de dados até a implementação final. Conforme abordado por \citeonline{geron2017} e \citeonline{muller2017}, essas etapas fornecem a base para decisões estratégicas ao longo do desenvolvimento do modelo.  Isso envolve determinar como a solução será utilizada, identificar o tipo de problema (como classificação ou regressão) e escolher métricas de desempenho que estejam alinhadas aos objetivos esperados \cite{geron2017}. O primeiro passo é estabelecer claramente o objetivo em termos de negócio e pesquisa. 

Além disso, é importante avaliar as soluções existentes ou alternativas em uso, que podem servir como ponto de comparação para medir o impacto do modelo. Também é necessário validar hipóteses iniciais sobre os dados e a abordagem, garantindo que o problema esteja bem estruturado e que as limitações sejam compreendidas desde o início. Segundo \citeonline{muller2017}, uma compreensão profunda dos dados e suas características é essencial para a escolha dos algoritmos e para o sucesso do projeto. Perguntas como “Quantos dados possuo?”, “Há dados faltantes?” e “Esses dados são suficientes para responder às perguntas do projeto?” guiam essa análise \cite{muller2017}.

Por fim, essa etapa também exige atenção ao alinhamento entre o problema técnico e os resultados esperados em termos de negócio ou impacto social. Isso garante que o desenvolvimento não seja apenas tecnicamente sólido, mas também relevante e eficaz em seu contexto de aplicação.

\subsection{Obtenção de Dados}
A etapa de obtenção de dados é um dos pilares fundamentais para o sucesso de um projeto de aprendizado de máquina, pois a qualidade e a relevância das informações coletadas impactam diretamente a eficácia do modelo \cite{geron2017}. O processo começa com a identificação e a listagem dos dados necessários, levando em conta sua quantidade e suas características, como formato, tipo e origem \cite{geron2017}. É igualmente importante garantir que as fontes de dados sejam documentadas, que haja espaço suficiente para armazenamento e que os dados estejam acessíveis de maneira eficiente.

Nessa etapa, é imprescindível observar as obrigações legais e éticas, especialmente as previstas na Lei Geral de Proteção de Dados (LGPD) no Brasil. Isso abrange a obtenção de consentimentos adequados para o uso das informações e a aplicação de medidas de segurança, como a anonimização, para proteger dados sensíveis \cite{muller2017}. Conforme destacado por \citeonline{muller2017}, além de cumprir os requisitos legais, é fundamental assegurar a integridade e a privacidade dos dados, principalmente em situações que envolvam informações pessoais ou confidenciais.

Para mitigar os desafios relacionados à qualidade dos dados, \citeonline{geron2017} sugere o uso de técnicas como a limpeza, normalização e engenharia de atributos. Além disso, ele ressalta a importância de práticas contínuas de validação, como a separação adequada entre conjuntos de treinamento e teste, garantindo que o modelo seja testado em dados que nunca encontrou antes. Dessa forma, a abordagem holística para o gerenciamento de dados reforça o desenvolvimento de sistemas robustos, confiáveis e éticos em projetos de Aprendizado de Máquina \cite{geron2017}.

\subsection{Exploração de Dados}
A obtenção e a exploração de dados representam etapas essenciais para o sucesso de projetos de aprendizado de máquina, pois determinam a base sobre a qual os modelos serão desenvolvidos \cite{geron2017}. Antes de preparar os dados para os algoritmos, é essencial entender as características e as relações existentes no conjunto de dados, iniciando a exploração com uma cópia dos dados originais, reduzindo sua escala, se necessário, para facilitar a análise inicial \cite{geron2017}.

A exploração dos dados deve seguir uma abordagem sistemática que envolve:

\begin{enumerate}
    \item \textbf{Estudo das características dos atributos:} Identificar o nome, o tipo (categórico, numérico, texto, etc.), o percentual de valores ausentes, o nível de ruído (outliers, erros de arredondamento), a utilidade potencial para a tarefa e o tipo de distribuição (gaussiana, uniforme, logarítmica) dos dados disponíveis.
    \item \textbf{Identificação de atributos-alvo:} No caso de aprendizado supervisionado, determinar qual atributo será o alvo da predição.
    \item \textbf{Visualização de dados:} Criar gráficos de dispersão, histogramas ou outros métodos visuais para identificar padrões, correlações e tendências. \citeonline{geron2017} sugere, por exemplo, experimentar combinações de atributos, como comparar o número de quartos por domicílio, em vez de analisar apenas o número total de quartos.
    \item \textbf{Correlação entre atributos:} Analisar as relações entre as variáveis para identificar combinações promissoras que possam melhorar a precisão do modelo.
\end{enumerate}

\citeonline{muller2017} destaca que a inspeção visual dos dados é essencial para compreender sua estrutura e identificar inconsistências, como unidades de medida divergentes ou valores inesperados, comuns em cenários reais. Ele recomenda o uso de gráficos de dispersão para analisar relações entre dois atributos ou gráficos de pares para explorar múltiplas combinações quando o número de variáveis é pequeno. Essa etapa também permite verificar se o problema pode ser resolvido manualmente, validando se as informações necessárias estão presentes no conjunto de dados.

Além disso, \citeonline{geron2017} ressalta a importância de aplicar transformações aos atributos, criando variáveis derivadas mais relevantes, como "população por domicílio", em vez de usar dados brutos. Ele também enfatiza a necessidade de documentar aprendizados e, se necessário, ajustar o escopo do projeto para incluir dados adicionais que possam melhorar os resultados. Essas práticas tornam a análise de dados uma etapa crucial para preparar modelos robustos e aumentar as chances de sucesso no projeto.

\subsection{Preparação dos dados para os Algoritmos de Aprendizado de Máquina}
A preparação dos dados para algoritmos de aprendizado de máquina é uma etapa essencial que envolve diversas transformações. Para tornar o processo mais eficiente, é recomendável criar funções específicas para realizar essas transformações, o que permite aplicá-las facilmente em novos conjuntos de dados e reutilizá-las em projetos futuros \cite{geron2017}. Entre as principais transformações, destaca-se a limpeza dos dados, que envolve lidar com valores ausentes. Para atributos com valores ausentes existem três opções: eliminar os registros correspondentes, excluir o atributo inteiro ou substituir os valores faltantes por uma constante, como a média ou a mediana \cite{geron2017}. 

Outro aspecto crucial na preparação dos dados é a escalabilidade dos atributos. Muitos algoritmos de aprendizado de máquina não funcionam bem quando as variáveis numéricas têm escalas muito diferentes \cite{geron2017}. Recomenda-se o uso de técnicas de escalonamento de atributos, como a normalização, que ajusta os valores para um intervalo de 0 a 1, ou a padronização, que ajusta os dados para ter média zero e variância unitária \cite{geron2017}. A escolha entre essas duas técnicas depende das características do algoritmo utilizado, já que a padronização é menos afetada por outliers e pode ser mais indicada em certos casos, como em redes neurais. A partir desse processo de preparação, o próximo passo é a seleção de modelos promissores, onde o uso de validação cruzada e a análise dos erros dos modelos ajudam a refinar a escolha do modelo mais adequado para o problema em questão \cite{geron2017}.

\subsection{Seleção e treinamento do modelo}
A seleção e o treinamento de modelos em aprendizado de máquina são etapas essenciais para desenvolver soluções eficazes \cite{geron2017}. Após a preparação dos dados, que inclui a exploração e a transformação, o próximo passo é escolher e treinar um modelo adequado. Para isso, um modelo simples pode ser treinado no conjunto de dados, permitindo observar sua performance inicial \cite{geron2017}. No entanto, para uma avaliação mais precisa, a validação cruzada é uma abordagem melhor. Essa técnica divide o conjunto de treinamento em K subconjuntos e, em seguida, treina e avalia o modelo várias vezes, usando um subconjunto diferente para validação a cada vez, o que gera uma estimativa mais confiável da performance do modelo \cite{geron2017}.

Uma alternativa eficaz para melhorar o desempenho do modelo é combinar múltiplas árvores de decisão de forma sequencial, onde cada árvore é treinada para corrigir os erros das anteriores, melhorando a acurácia e reduzindo o risco de overfitting, como o Gradient Boosting \cite{geron2017}. A abordagem de treinar múltiplos modelos com parâmetros padrão e avaliá-los usando validação cruzada permite selecionar as melhores opções para o problema em questão \cite{geron2017}.

Além disso, para aprimorar a performance do modelo, é fundamental realizar uma análise das variáveis mais relevantes e ajustar as características dos dados \cite{geron2017}. A engenharia de atributos e a seleção de features permitem que os modelos se ajustem para cometer diferentes tipos de erros, o que ajuda a melhorar a precisão geral. Essas etapas devem ser repetidas de forma iterativa, ajustando o modelo com base nas análises de erros e nas mudanças nos dados, o que possibilita a evolução do desempenho do modelo ao longo do processo \cite{geron2017}.

No caso de problemas de classificação, o \textit{algoritmo k-vizinhos mais próximos (k-NN}) é uma das opções mais simples e eficazes \cite{muller2017}. Esse modelo faz previsões baseadas na proximidade dos dados de treinamento, atribuindo o rótulo da classe mais comum entre os vizinhos mais próximos de um ponto desconhecido \cite{muller2017}. A definição do parâmetro 'k', que determina quantos vizinhos são considerados, pode ser ajustada para otimizar os resultados. A implementação do \textit{KNeighborsClassifier} no \textit{Scikit-learn} facilita a criação e a avaliação do modelo, tornando-o uma excelente escolha para tarefas de classificação simples \cite{muller2017}.

\subsection{Ajuste do modelo}

O processo de ajuste fino de modelos (fine-tuning) é uma etapa crucial no desenvolvimento de modelos de aprendizado de máquina, especialmente após a seleção de modelos promissores \cite{geron2017}. Uma das abordagens mais comuns para realizar esse ajuste é o uso de \textit{GridSearchCV do Scikit-Learn}, que automatiza a busca pelos melhores hiperparâmetros do modelo. Em vez de testar manualmente combinações de valores para os hiperparâmetros, o \textit{GridSearchCV} avalia todas as possibilidades de uma lista de valores, utilizando validação cruzada para escolher a melhor configuração \cite{geron2017}. Isso facilita o processo, economizando tempo e aumentando a precisão na escolha dos parâmetros ideais para o modelo.

No entanto, para espaços de busca de hiperparâmetros maiores, a \textit{RandomizedSearchCV} pode ser uma alternativa mais eficiente. Em vez de testar todas as combinações possíveis, essa abordagem realiza uma busca aleatória, selecionando valores aleatórios para cada hiperparâmetro em cada iteração \cite{geron2017}. Essa técnica oferece duas grandes vantagens: a possibilidade de explorar um maior número de combinações de hiperparâmetros dentro de um orçamento computacional limitado, além de permitir um controle mais flexível sobre o número de iterações realizadas (Géron, 2017). Dessa forma, a \textit{RandomizedSearchCV} é especialmente útil quando o espaço de busca é grande e as combinações possíveis são muitas \cite{geron2017}.

Além do ajuste de hiperparâmetros, outra técnica importante para aprimorar o modelo é o uso de \textit{Métodos de Ensemble}. Esses métodos combinam os melhores modelos individuais, muitas vezes resultando em um desempenho superior ao de qualquer modelo isolado \cite{geron2017}. A combinação de modelos com erros diferentes pode reduzir a variabilidade e melhorar a precisão geral. Um exemplo clássico é o \textit{Random Forest}, que utiliza múltiplas árvores de decisão para obter melhores resultados do que uma única árvore. A estratégia de ensemble pode ser fundamental para melhorar o desempenho do modelo, especialmente em tarefas complexas \cite{geron2017}.

Após o ajuste fino, é importante analisar os melhores modelos e seus erros para entender melhor o desempenho do sistema. Inspecionar os atributos mais importantes para a previsão pode revelar insights valiosos sobre o problema \cite{muller2017}. Além disso, entender os tipos de erros cometidos pelo modelo e as razões por trás deles pode ajudar a ajustar o modelo, adicionando ou removendo features, tratando outliers ou refinando a transformação dos dados \cite{muller2017}. Finalmente, após realizar todas essas melhorias, o modelo deve ser avaliado no conjunto de teste para estimar sua capacidade de generalização. A avaliação no conjunto de teste fornece uma medida objetiva da performance do modelo em dados não vistos, sendo fundamental para garantir que o modelo não esteja superajustado aos dados de treinamento \cite{muller2017}.

\subsection{Lançamento da Solução}
Após a aprovação do lançamento de um projeto, é crucial preparar a solução para produção, conectando as fontes de dados de entrada e escrevendo os testes necessários para garantir que o sistema funcione conforme esperado. A integridade e a qualidade do sistema, bem como sua adaptação ao ambiente de produção, são essenciais para que ele se mantenha eficiente. Além disso, é necessário implementar códigos de monitoramento que acompanhem a performance do sistema em tempo real, verificando se ele continua operando de maneira eficiente e acionando alertas sempre que houver uma queda na performance \cite{geron2017}. Isso é especialmente importante, pois os modelos de aprendizado de máquina podem sofrer uma degradação gradual ao longo do tempo devido à mudança nos dados, o que é conhecido como "data drift" \cite{geron2017}.

Para garantir a qualidade das previsões, o monitoramento também deve incluir uma avaliação humana periódica, muitas vezes realizada por analistas ou por meio de plataformas de \textit{crowdsourcing}, como o \textit{Amazon Mechanical Turk ou o CrowdFlower}. Essa análise ajuda a validar se o modelo continua atendendo às expectativas e fornece informações cruciais sobre possíveis melhorias  \cite{muller2017}. A qualidade dos dados de entrada também deve ser constantemente monitorada, já que problemas como sensores defeituosos ou dados desatualizados podem impactar significativamente a acuracidade do modelo, prejudicando sua performance e a confiança nos resultados gerados  \cite{muller2017}.

A manutenção do sistema é outro aspecto crítico após o lançamento, exigindo que o modelo seja re-treinado regularmente com dados frescos \cite{geron2017}. Isso é importante para evitar que a performance do sistema flutue de forma inesperada, o que pode acontecer se o modelo for atualizado de maneira esporádica \cite{geron2017}. A automação desse processo de re-treinamento é essencial para garantir que o modelo seja atualizado sempre que necessário, sem depender de intervenções manuais. 

Portanto, o lançamento de um sistema de aprendizado de máquina não se limita à integração inicial dos dados e à validação do modelo. O sucesso contínuo depende de um monitoramento eficiente e de uma manutenção constante, garantindo que o modelo se adapte às mudanças nos dados ao longo do tempo. Implementando uma infraestrutura de monitoramento e re-treinamento robusta, as equipes podem assegurar que o sistema continue atendendo aos objetivos de negócios de forma eficaz e precisa, minimizando riscos e maximizando a performance ao longo de sua vida útil.


\section{Fases de Trabalho}

As fases do nosso trabalho se dividem em duas etapas: \textbf{Fase 1: Análise e Preparação de Dados} (Tabela \ref{tab:fase1}), com o objetivo de compreender e organizar os dados para realizar a análise da influência dos parâmetros na porcentagem de euploidia, e a \textbf{Fase 2: Desenvolvimento e Avaliação do Modelo} detalhada na Tabela (Tabela \ref{tab:fase2}), que foca no desenvolvimento, ajuste e avaliação de um modelo de ML para efetuar a predição de euploidia, finalizando com a entrega de um protótipo de uma interface a ser evoluída em trabalhos futuros, realizando a criação e junção dos dois.

Nas seções a seguir, demonstraremos os objetivos de cada fase, mostrando suas atividades, nas quais estão descritos resumidamente o que será feito, qual método será utilizado e o resultado esperado. Em seguida, detalharemos cada parte.

\begin{table}[h!]
  \centering
  \renewcommand{\arraystretch}{1.4} 
  \captionsetup{font=footnotesize, justification=centering, labelsep=period, position=above}
  \caption{Fase 1: Análise e Preparação de Dados}
  \label{tab:fase1}
  \resizebox{\textwidth}{!}{ 
    \begin{tabular}{|p{3cm}|p{4cm}|p{3cm}|p{5cm}|} 
      \hline
      \multicolumn{4}{|c|}{\cellcolor[HTML]{008940} \textbf{Fase 1: Análise e Preparação de Dados}} \\
      \hline

      \cellcolor[HTML]{C0C0C0} \textbf{Objetivos Específicos} & 
      \cellcolor[HTML]{C0C0C0} \textbf{Atividades} & 
      \cellcolor[HTML]{C0C0C0} \textbf{Método de Pesquisa} & 
      \cellcolor[HTML]{C0C0C0} \textbf{Resultados Esperados} \\
      \hline

      \multirow{4}{*}{
          \parbox[c]{\linewidth}{
          \centering
          \vspace{0.2cm}
          \hspace{0.1cm}\textcolor[HTML]{133E78}{\textbf{
            OE1 \\[0.1cm]
            Expansão, \\[0.1cm]
            Processamento e \\[0.1cm]
            Análise de \\[0.1cm]
            Dados para \\[0.1cm]
            Predição de \\[0.1cm]
            Ploidia
          }}\hspace{0.1cm}
        }
      }
      &
      \textcolor[HTML]{133E78}{\textbf{Atividade 1 (A1)}} \newline
      Análise, Revisão e Seleção de Variáveis para Predição de Euploidia &
      - Pesquisa bibliográfica \newline
      - Python - Biblioteca Pandas &
      - Analisar, Revisar e Selecionar as variáveis \newline
      - Limpeza dos dados \\
      \cline{2-4}

      & 
      \textcolor[HTML]{133E78}{\textbf{Atividade 2 (A2)}} \newline
      Normalização dos Dados para Otimização &
      - Z-Score &
      - Normalização das variáveis numéricas \\
      \cline{2-4}

      & 
      \textcolor[HTML]{133E78}{\textbf{Atividade 3 (A3)}} \newline
      Identificação da Correlação e Atribuição de Pesos aos Parâmetros na Previsão da Ploidia do Embrião &
      - Coeficiente de correlação de Spearman &
      - Análise das correlações entre variáveis pelo Gráfico de dispersão \\
      \cline{2-4}

      & 
      \textcolor[HTML]{133E78}{\textbf{Atividade 4 (A4)}} \newline
      Divisão de Dados e Aplicação de Data Augmentation & 
      - Divisão do conjunto de dados \newline
      - Data augmentation com o Algoritmo de Monte Carlo &
      - Dados para treinamento e teste \newline
      - Aumento do conjunto de dados para treinamento \\
      \hline
    \end{tabular}
  }
\end{table}
\FloatBarrier 

\subsection{\textbf{Objetivo Específico 1} - Identificação de Parâmetros em Embriões}

\subsubsection{\textbf{Atividade 1 (A1):} Análise, Revisão, Seleção e Limpeza de Variáveis para Predição de Euploidia}

Começaremos com a verificação da pertinência das variáveis já existentes na planilha de dados dos embriões e com a avaliação da introdução de outras variáveis que possam aprimorar a exatidão da análise, ou até mesmo com a eliminação de variáveis, se necessário. Em seguida, faremos a limpeza dos dados, substituindo valores nulos por valores mais apropriados em alguns casos, como nas colunas que realizam cálculos entre outras colunas, onde será possível identificar valores e substituí-los.

Para realizar a verificação da pertinência das variáveis já existentes e avaliar a viabilidade de introduzir novas variáveis, utilizaremos a pesquisa bibliográfica, nos norteando pelos estudos apresentados no capítulo 2: o de \citeonline{yuan2023}, o artigo 'Development of an artificial intelligence-based model for predicting the euploidy of blastocysts in PGT-A treatments' e o de \citeonline{souzarebeca2022}, 'Análise da ploidia de embriões humanos por meio da inteligência artificial com o uso de variáveis de morfologia, morfocinética e variáveis relacionadas com a paciente'. Ambos os artigos descrevem o uso de IA para fazer a predição da ploidia de embriões, o que se assemelha com o que queremos propor, com a diferença de que temos o objetivo final de prever a porcentagem de aneuploidia. 

Dessa forma, analisaremos os estudos feitos por ambos pesquisadores e utilizaremos para entender o poder que cada variável tem para o objetivo final e se é necessário adicionar outras variáveis que não existem na nossa planilha, ou até mesmo excluí-las. Além disso, conduziremos entrevistas com o especialista encarregado de fornecer os dados, para uma análise prática da pertinência das variáveis disponíveis e para debater possíveis variáveis extras que possam ser relevantes para a análise. As entrevistas possibilitarão alinhar a seleção das variáveis ao conhecimento clínico e experiência prática do profissional, garantindo que as variáveis selecionadas sejam aplicáveis no cenário real de previsão de euploidia. Em relação a limpeza dos dados, utilizaremos a linguagem \textit{Python} que possui a biblioteca \textit{Pandas}, que permite o carregamento de planilhas do Excel, do formato .xlsx, como a que possuímos. De acordo com \citeonline{chen2018}: “O Pandas é uma biblioteca Python de código aberto para análise de dados. Ele dá a Python a capacidade de trabalhar com dados do tipo planilha, permitindo carregar, manipular, alinhar e combinar dados rapidamente, entre outras funções.”.Usaremos as funções \textit{isnull()} e \textit{info()}, da biblioteca \textit{Pandas}.

Inicialmente, analisar as variáveis possibilitando a detecção de variáveis irrelevantes ou redundantes, aprimorando a correlação entre os parâmetros estudados e a percentagem de euploidia. Também a detecção e correção de inconsistências, como valores em branco ou discrepâncias, garantindo que o conjunto de dados esteja organizado e pronto para futuras análises, prevenindo distorções nos resultados. 

\paragraph{\textbf{Atividade 2 (A2):} Normalização dos Dados para Otimização}

Antes de iniciarmos a normalização, algumas variáveis serão transformadas para o formato numérico, pois estão originalmente representadas como strings. A primeira variável a ser alterada será a ploidia, que será convertida para valores binários: 0 para euploide e 1 para aneuploide. Em seguida, a variável estágio será modificada removendo-se a letra “D” e mantendo apenas o número que representa o dia de desenvolvimento embrionário, como 5, 6 ou 4. Por fim, a variável classificação Morfo será substituída pelo seu grupo numérico equivalente, conforme descrito no referencial teórico, com valores de 1 a 4.

As variáveis numéricas são normalizadas, por meio de uma técnica de normalização, o \textbf{Z-Score}, assegurando os intervalos de valores de cada coluna. normalização será essencial, pois, de acordo com \citeonline{milewski2016}, estudos anteriores demonstraram que a incorporação de dados morfológicos normalizados na avaliação da qualidade embrionária aumenta consideravelmente o poder preditivo dos modelos construídos. A normalização é uma forma de dimensionar recursos, transformando o intervalo deles em uma escala padrão \cite{jaiswal2024}. Essa técnica transformará os dados para uma escala padrão \cite{jaiswal2024}, facilitando a interpretação e a comparação entre diferentes variáveis. Quando todas as características do conjunto de dados estiverem na mesma escala, será mais fácil visualizar relações, realizar comparações significativas e reduzir vieses numéricos.

Utilizaremos o método Z-Score, detalhado no APÊNDICE \ref{apendice:zscore}. Essa normalização garantirá que todas as variáveis estejam adequadamente padronizadas, aprimorando a exatidão dos algoritmos de aprendizado de máquina que serão implementados posteriormente.

\paragraph{\textbf{Atividade 3 (A3):} Identificação da Correlação e Atribuição de Pesos aos Parâmetros na Previsão da Ploidia do Embrião}

O objetivo desta atividade é identificar as relações entre os diferentes parâmetros presentes na planilha de dados dos embriões, avaliando a intensidade e o sentido dessas relações, com foco em sua influência na porcentagem de euploidia. Após a pesquisa bibliográfica, utilizaremos o coeficiente de correlação de Spearman, que mede a relação monótona entre duas variáveis, considerando as ordens atribuídas às observações em vez dos valores originais \cite{sousa2019}. A correlação será calculada para todas as combinações possíveis de variáveis, possibilitando uma análise mais detalhada de suas interações \cite{sousa2019}. Um gráfico de dispersão será gerado para complementar a análise visual, facilitando a identificação de padrões. Também com o conhecimento adquirido pela A1, determinaremos a relevância relativa de cada parâmetro na previsão da ploidia do embrião, atribuindo pesos que reflitam sua influência, identificando a relevância de cada parâmetro.

Para realizar a análise de correlação entre os parâmetros será utilizado o coeficiente de Spearman, um método estatístico amplamente empregado para avaliar a intensidade e o sentido da relação monótona entre duas variáveis. Inicialmente, as variáveis do conjunto de dados serão classificadas em ordem crescente, atribuindo-lhes ranks que serão usados para o cálculo do coeficiente. Essa abordagem permite capturar relações tanto lineares quanto não lineares entre as variáveis \cite{sousa2019}, explicado com mais detalhes no APÊNDICE \ref{apendice:spearman}. 

A fórmula do coeficiente de correlação de Spearman será aplicada, utilizando as ordens atribuídas, assegurando que o método se adapte a diferentes formatos de relação, como curvas monótonas crescentes ou decrescentes. Além disso, será realizada uma análise complementar com gráficos de dispersão, que ajudarão a identificar a inclinação dos dados e o sentido da correlação, sendo positiva (próximas ao valor 1) quando as variáveis variam no mesmo sentido e negativa (próximas ao valor -1) quando variam em sentidos opostos \cite{sousa2019}. O resultado numérico do coeficiente será avaliado em relação à sua magnitude, indicando se a correlação é forte, moderada ou fraca, e seu sinal indicará o tipo de relação (positiva ou negativa). 

Usaremos a biblioteca Pandas para manipulação dos dados e a SciPy para calcular o coeficiente de Spearman. A metodologia para a definição e atribuição de pesos específicos aos parâmetros relevantes para a ploidia do embrião combina análise teórica e prática. Inicialmente, será realizada uma pesquisa bibliográfica em publicações científicas e revisões sistemáticas que explorem a influência dos parâmetros na ploidia embrionária.

Os cálculos realizados com o coeficiente de Spearman permitirão identificar quais parâmetros possuem uma relação mais forte (positiva ou negativa) com a porcentagem de euploidia, além de explorar como esses parâmetros se relacionam entre si. Os gráficos gerados deverão destacar as variáveis mais influentes, os padrões visuais que reforcem as relações monótonas, áreas onde a ausência de correlação linear não exclua outras formas de relação. Também resultará em uma lista detalhada dos parâmetros identificados, acompanhada das respectivas justificativas para os pesos atribuídos a cada um, com base em sua influência na ploidia do embrião. Em vez de valores numéricos, os resultados trarão explicações fundamentadas cientificamente, apresentando as razões pelas quais cada parâmetro exerce determinada influência. O resultado final fornecerá uma visão qualitativa e consistente dos fatores que impactam a ploidia, sendo uma base essencial para análises e decisões futuras no estudo.

\paragraph{\textbf{Atividade 4 (A4):} Separar o conjunto de dados em conjuntos de treinamento e teste, fazendo uma distribuição dos dados e aplicar técnica de aumento de dados}

A aplicação de técnicas de Aprendizado de Máquina em conjuntos de dados pequenos impõe desafios metodológicos significativos. Nesses cenários, o risco de overfitting (sobreajuste) é amplificado. Esse fenômeno ocorre quando o modelo aprende padrões específicos e ruídos do conjunto de treinamento, em vez de generalizações úteis para novos dados, resultando em uma performance artificialmente elevada durante o treinamento, mas fraca diante de dados independentes \cite{bashir2020}.

Como o tamanho do conjunto de dados inviabiliza uma divisão tradicional em três subconjuntos (treinamento, validação e teste), optamos por uma abordagem mais viável: a divisão em apenas dois conjuntos — 80\% para treinamento e 20\% para teste. Essa decisão visa preservar a maior quantidade possível de dados para o treinamento, garantindo ao mesmo tempo uma avaliação minimamente robusta do desempenho do modelo. \citeonline{andrew2018} sugere que conjuntos de dados menores que 10.000, a divisão deve ser cuidadosamente ponderada, pois qualquer porção reservada a validação pode comprometer a capacidade de aprendizado e a confiabilidade da avaliação.

Além da divisão, será feito um \textbf{balanceamento das classes} durante a divisão dos dados, a fim de garantir que a escolha aleatória não acabe segregando mais amostras de uma classe em um conjunto do que em outro. Esse cuidado é essencial para evitar viés nos dados e assegurar que o modelo tenha a oportunidade de aprender e ser avaliado com amostras representativas de todas as classes, o que pode impactar diretamente na precisão do modelo.

Dado o volume reduzido de dados, aplicamos a técnica de aumento de dados (data augmentation), utilizando o algoritmo de Monte Carlo (ver APÊNDICE \ref{apendice:montecarlo}), com o objetivo de gerar amostras sintéticas de alta qualidade a partir dos dados existentes. Essa técnica foi aplicada exclusivamente ao conjunto de treinamento, de forma a evitar interferências na avaliação final e permitir que o modelo aprenda a partir de padrões legítimos.  

% A separação do conjunto de dados será feita para garantir que as etapas de treinamento e testes sejam realizadas de forma organizada. Iremos dividir em 2 conjuntos: \textbf{Treinamento}, para ensinar o modelo e ajustar os parâmetros de forma adequada, evitando o overfitting — que ocorre quando um algoritmo reduz o erro por meio da memorização de exemplos de treinamento, em vez de aprender a verdadeira relação geral entre os dados \cite{bashir2020} —; e \textbf{Teste}, para avaliar o desempenho final. A divisão será realizada com uma distribuição de 80\% dos dados para treinamento e 20\% para teste.

% Além disso, será feito um \textbf{balanceamento das classes} durante a divisão dos dados, a fim de garantir que a escolha aleatória não acabe segregando mais amostras de uma classe em um conjunto do que em outro. Esse cuidado é essencial para evitar viés nos dados e assegurar que o modelo tenha a oportunidade de aprender e ser avaliado com amostras representativas de todas as classes, o que pode impactar diretamente na precisão do modelo.

% Nosso conjunto de dados original é relativamente pequeno, contendo apenas 84 linhas. Por isso, aplicaremos a técnica de \textbf{aumento de dados (data augmentation)} utilizando o algoritmo Monte Carlo (APÊNDICE \ref{apendice:montecarlo}), que gera novas amostras a partir de dados existentes. Utilizaremos essa técnica exclusivamente nos dados de treinamento, a fim de evitar interferências negativas na avaliação e garantir que o modelo aprenda a partir de padrões legítimos dos dados \cite{kiar2021}.

% Para a realização, será usada uma abordagem padrão em aprendizado de máquina, dividindo o conjunto de dados em dois subconjuntos, conforme descrito. Essa divisão é feita para garantir que o modelo seja avaliado de forma imparcial e com base em dados não vistos durante o treinamento \cite{bashir2020}. Para ampliar o conjunto de treinamento, será aplicada a técnica de aumento de dados com Monte Carlo, que permite a geração de dados artificiais de alta qualidade por meio da manipulação de amostras existentes \cite{wang2024}. 

% O resultado esperado é a divisão do conjunto de dados em dois subconjuntos: treinamento (com aumento de dados) e teste (com dados originais apenas), assegurando uma avaliação justa e a construção de um modelo robusto de aprendizado de máquina.

\begin{table}[h!]
  \centering
  \renewcommand{\arraystretch}{1.4} 
  \captionsetup{font=footnotesize, justification=centering, labelsep=period, position=above}
  \caption{Fase 2: Desenvolvimento e Avaliação do Modelo}
  \label{tab:fase2}
  \resizebox{\textwidth}{!}{ 
    \begin{tabular}{|p{3cm}|p{4cm}|p{3cm}|p{5cm}|} 
      \hline
      \multicolumn{4}{|c|}{\cellcolor[HTML]{008940} \textbf{Fase 2: Desenvolvimento e Avaliação do Modelo}} \\
      \hline

      \cellcolor[HTML]{C0C0C0} \textbf{Objetivos Específicos} & 
      \cellcolor[HTML]{C0C0C0} \textbf{Atividades} & 
      \cellcolor[HTML]{C0C0C0} \textbf{Método de Pesquisa} & 
      \cellcolor[HTML]{C0C0C0} \textbf{Resultados Esperados} \\
      \hline

      % --- Seção OE2 ---
          \centering
          \hspace{0.1cm}\textcolor[HTML]{133E78}{\textbf{
            OE2 \\[0.1cm]
            Treinamento e \\[0.1cm]
            Ajuste de Modelo \\[0.1cm]
            de Machine \\[0.1cm]
            Learning para \\[0.1cm]
            Predição de \\[0.1cm]
            Euploidia
          }}\hspace{0.1cm}
      &
      \textcolor[HTML]{133E78}{\textbf{Atividade 5 (A5)}} \newline
      Desenvolvimento e Treinamento do Modelo de Machine Learning para Otimização da Predição de Euploidia &
      - Python (Bibliotecas scikit-learn) &
      - Treinamento do modelo bem-sucedido com no mínimo 70\% de precisão, usando KNN, regressão linear e naive bayes \\
      \hline

      % --- Seção OE3 ---
      \multirow{2}{*}{
          \parbox[c]{\linewidth}{
              \vspace{0.2cm}
              \centering
              \hspace{0.1cm}\textcolor[HTML]{133E78}{\textbf{
                OE3 \\[0.1cm]
                Avaliação do Modelo
              }}\hspace{0.1cm}
          }
      }
      & 
      \textcolor[HTML]{133E78}{\textbf{Atividade 6 (A6)}} \newline
      Utilizar métricas adequadas para medir o desempenho do modelo &
      - Python (Biblioteca scikit-learn e pandas) &
      - Acurácia \newline
      - Precisão \newline
      - Recall \newline
      - F1-Score \\
      \cline{2-4}

      & 
      \textcolor[HTML]{133E78}{\textbf{Atividade 7 (A7)}} \newline
      Avaliação do Desempenho do Modelo na Predição por Meio da Matriz de Confusão e Curva ROC &
      - Matriz de confusão (Random Forest - scikit-learn) &
      - Verdadeiros positivos (TP) \newline
      - Verdadeiros negativos (TN) \newline
      - Falsos positivos (FP) \newline
      - Falsos negativos (FN) \newline
      - Gráfico exibindo a relação entre a sensibilidade e a especificidade para diferentes valores de limiar. \\
      \hline

      % --- Seção OE4 ---
      \parbox[c]{\linewidth}{
        \vspace{0.2cm}
        \centering
        \textcolor[HTML]{133E78}{\textbf{
          OE4 \\[0.1cm]
          Protótipo de \\[0.1cm]
          Interface
        }}
      }
      & 
      \textcolor[HTML]{133E78}{\textbf{Atividade 8 (A8)}} \newline
      Prototipar uma interface &
      - Interface básica desenvolvida no FIGMA &
      - Interface básica \newline
      - Coleta de opiniões \\
      \hline
    \end{tabular}
  }
\end{table}
\FloatBarrier


\subsubsection{\textbf{Objetivo Específico 2} - Treinamento e Ajuste de Modelo de Machine Learning para Predição de Euploidia}

\paragraph{\textbf{Atividade 5 (A5):} Desenvolvimento e Treinamento do Modelo de Machine Learning para Otimização da Predição de Euploidia}

O modelo de Machine Learning para predição de euploidia será desenvolvido em etapas, começando pelo uso do algoritmo k-Nearest Neighbors (KNN), escolhido por sua simplicidade e bom desempenho em tarefas de classificação com dados bem distribuídos. O objetivo é classificar embriões como euploides ou aneuploides com, no mínimo, 70\% de precisão.

Caso o KNN não atinja esse desempenho, outras abordagens serão testadas: regressão logística, adaptada para classificação binária, e o classificador Naive Bayes, conhecido por sua eficiência em conjuntos com atributos independentes \cite{zhang2016, rodrigues, rish2001}. Todos os modelos serão treinados e avaliados utilizando os dados já pré-processados na Atividade 3, com normalização adequada, especialmente importante para o KNN, pois este modelo é sensível à escala dos dados \cite{zhang2016}.

Inicialmente, utilizaremos o \textit{KNeighborsClassifier} do \textit{Scikit-learn}. O primeiro passo será definir o número de vizinhos (n\_neighbors), um dos parâmetros mais importantes do KNN \cite{zhang2016}. Para isso,  utilizaremos um valor de k igual a 3 para o número de vizinhos, devido à sua simplicidade e aplicabilidade comprovada em problemas semelhantes. Caso a precisão fique abaixo de 70\%, o valor de k será ajustado (por exemplo, para 5) em busca de melhor desempenho. A seguir, será avaliada a \textit{LogisticRegression} e, se necessário, o \textit{NaiveBayes}, ambos também do \textit{Scikit-learn}, com ajustes conforme os resultados nos dados de teste.

A avaliação final do modelo será feita na Atividade 6, onde a precisão dos diferentes modelos será comparada. Nosso objetivo é alcançar uma precisão de 70\% na classificação dos embriões como euploides ou aneuploides. Caso nenhuma das técnicas anteriores atinja a precisão mínima exigida, redes neurais artificiais serão consideradas como alternativa final. Apesar de mais complexas, elas oferecem maior capacidade de modelar padrões não lineares, o que pode ser vantajoso neste problema \cite{russell2016}.

Ao final, espera-se obter um modelo capaz de classificar embriões com pelo menos 70\% de precisão, fornecendo uma base confiável para apoio a decisões clínicas e pesquisas científicas.

\subsubsection{\textbf{Objetivo Específico 3} - Avaliação do modelo}

\paragraph{\textbf{Atividade 6 (A6):} Utilizar métricas de avaliação mais adequadas para medir o desempenho do modelo de acordo com a natureza do problema de classificação}

O objetivo desta atividade é aplicar e avaliar métricas adequadas para medir o desempenho e a confiabilidade de um modelo de IA considerando as particularidades do problema abordado. Serão utilizadas as métricas Acurácia, Precisão, \textit{Recall} (Sensibilidade), \textit{F1-Score} e \textit{ROC-AUC}. A análise será realizada com base em um conjunto de dados previamente definido, utilizando \textit{Python} e bibliotecas como \textit{scikit-learn} e \textit{pandas} para implementação, análise e visualização dos resultados.

Cada métrica será detalhada a seguir:

\begin{itemize}
    \item \textbf{Acurácia}: mede a proporção de previsões corretas em relação ao total de previsões realizadas. Essa métrica é útil em problemas com classes balanceadas e quando não há maior preocupação com erros específicos, como falsos positivos ou falsos negativos \cite{vilela2022}. Será calculada com a função \textit{accuracy\_score} do \textit{scikit-learn}.
    
    \item \textbf{Precisão}: avalia a proporção de exemplos classificados como positivos que realmente pertencem à classe positiva. É crucial em contextos onde falsos positivos têm consequências severas, como em diagnósticos médicos \cite{vilela2022}. Será calculada com a função \textit{precision\_score}.
    
    \item \textbf{\textit{Recall}}: mede a capacidade do modelo de identificar corretamente os exemplos pertencentes à classe positiva. É especialmente importante em situações onde falsos negativos têm maior impacto, como na detecção de aneuploidia de embriões \cite{vilela2022}. Será calculado com a função \textit{recall\_score}.
    
    \item \textbf{\textit{F1-Score}}: combina Precisão e \textit{Recall}, fornecendo uma visão equilibrada entre ambas \cite{vilela2022}. É particularmente relevante em casos onde as classes estão desbalanceadas e há necessidade de avaliar o desempenho geral do modelo. Será calculado com a função \textit{f1\_score}.
    
    \item \textbf{\textit{ROC-AUC}}: permite avaliar a capacidade geral do modelo de distinguir entre classes, mesmo quando estas estão desbalanceadas \cite{vilela2022}. Essa métrica complementa a análise das demais, oferecendo uma visão ampla do desempenho do classificador.
\end{itemize}

Espera-se que a análise dessas métricas proporcione uma avaliação abrangente do desempenho do modelo, destacando seus pontos fortes e limitações, e possibilitando ajustes para melhorar sua confiabilidade e alinhamento com os objetivos do problema. Além disso, a escolha criteriosa das métricas será essencial para orientar decisões estratégicas, especialmente em aplicações sensíveis a erros de classificação.

\paragraph{\textbf{Atividade 7 (A7):} Avaliar a precisão e eficácia do modelo em prever corretamente casos de euploidia e aneuploidia  por meio da Matriz de Confusão e Curva ROC}

O objetivo desta atividade é avaliar o desempenho do modelo de classificação desenvolvido para prever corretamente os casos de euploidia e aneuploidia, utilizando a Matriz de Confusão e a Curva ROC (Receiver Operating Characteristic). A Matriz de Confusão será construída após o treinamento e teste do modelo, permitindo identificar as taxas de verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos. Essa análise ajudará a compreender o desempenho geral do modelo e a identificar possíveis áreas de melhoria. Adicionalmente, será gerada a Curva \textit{ROC} para avaliar o desempenho do modelo na separação das duas classes: euploide (classe positiva) e aneuploide (classe negativa) \cite{vilela2022}. A curva será analisada com base em diferentes valores de limiar (threshold), fornecendo uma visão detalhada sobre a sensibilidade e a especificidade do modelo em cada ponto. A métrica AUC (Área sob a Curva) será utilizada como indicador global da capacidade do modelo de distinguir entre as classes, sendo especialmente útil para avaliar problemas de classificação desbalanceada \cite{vilela2022}.

A avaliação do desempenho do modelo será realizada em duas etapas principais: a construção da Matriz de Confusão e a geração da Curva ROC. A Matriz de Confusão é uma ferramenta essencial para entender o desempenho do modelo de classificação. De acordo com \citeonline{sathyanarayanan2024}, essa matriz é uma tabela de dimensão N x N, onde N representa o número de classes. Cada linha da matriz indica a quantidade de instâncias previstas em uma classe, enquanto cada coluna representa a quantidade de instâncias reais da classe. Para este estudo, a matriz permitirá a análise de predições corretas e incorretas, classificando-as como verdadeiros positivos (TP), verdadeiros negativos (TN), falsos positivos (FP) e falsos negativos (FN). 

A partir dessas classificações, podemos calcular diversas métricas importantes para medir a precisão do modelo, como a acurácia, precisão, \textit{recall} e \textit{F1-score}, que nos ajudam a identificar as áreas de melhoria no modelo de predição. Além disso, será utilizada uma Curva \textit{ROC} para avaliar o desempenho do modelo de forma mais detalhada. O modelo de classificação Random Forest será implementado utilizando a biblioteca \textit{scikit-learn}, que permite gerar probabilidades de pertença à classe positiva (euploide). A Curva ROC, que é fundamental para problemas de classificação binária, é baseada nessas probabilidades, em vez de apenas classificações binárias \cite{vilela2022}. 

A curva será gerada variando o limiar de decisão, (\textit{threshold}), do modelo. O limiar define a probabilidade a partir da qual uma instância será classificada como pertencente à classe positiva (euploide) \cite{vilela2022}. O threshold será ajustado para diferentes valores, e para cada um, será calculada a sensibilidade (taxa de verdadeiros positivos) e a especificidade (1 - taxa de falsos positivos) \cite{vilela2022}. Para isso, utilizaremos o método predict\_proba() do \textit{scikit-learn} para obter as probabilidades previstas pelo modelo. A função \textit{roc\_curve()} da biblioteca também será utilizada para calcular os valores de falso positivo e verdadeiro positivo para os diferentes limiares, gerando o gráfico da Curva \textit{ROC}, com a especificidade no eixo x e a sensibilidade no eixo y. 

Finalmente, a métrica \textit{AUC} (Área sob a Curva) será calculada utilizando a função \textit{roc\_auc\_score()} do \textit{scikit-learn}. A \textit{AUC}, que varia de 0 a 1, fornecerá uma avaliação quantitativa do modelo, sendo que valores mais próximos de 1 indicam um melhor desempenho na classificação. A Curva \textit{ROC}, junto com a \textit{AUC}, nos ajudará a entender o comportamento do modelo para diferentes limiares e a selecionar o melhor ponto de corte, equilibrando os \textit{trade-offs} entre a taxa de verdadeiros positivos e falsos positivos.

Ao construir a Matriz de Confusão, espera-se obter uma análise detalhada do desempenho do modelo, identificando os verdadeiros positivos (TP), verdadeiros negativos (TN), falsos positivos (FP) e falsos negativos (FN). Essa análise permitirá avaliar não apenas a precisão global do modelo, mas também as taxas de erro em diferentes categorias, como os casos de euploidia erroneamente classificados como aneuploidia (FP) e os de aneuploidia erroneamente classificados como euploidia (FN). Essa avaliação fornecerá subsídios para aprimoramentos no modelo de classificação. Para a Curva ROC, o gráfico gerado mostrará a relação entre a sensibilidade e a especificidade em diferentes valores de limiar. Espera-se que o modelo apresente uma curva ascendente, indicando sua capacidade de identificar corretamente os positivos (euploide) sem gerar muitos falsos positivos. O valor da AUC (Área sob a Curva) será calculado para quantificar a habilidade do modelo em distinguir entre as classes \cite{vilela2022}. Valores de AUC próximos de 1 indicam um excelente desempenho do modelo, enquanto valores próximos de 0,5 sugerem que o modelo apresenta desempenho similar a uma escolha aleatória \cite{vilela2022}. A partir da Curva ROC, será possível selecionar o limiar mais adequado para balancear os erros de falso positivo e falso negativo, permitindo uma análise criteriosa dos trade-offs envolvidos \cite{vilela2022}. Esses resultados fornecerão uma base sólida para avaliar a eficácia do modelo e sua aplicabilidade no contexto do estudo.

\subsubsection{\textbf{Objetivo Específico 4} - Protótipo de Interface}

\paragraph{\textbf{Atividade 8 (A8):} Prototipar uma interface básica para exibir as predições de euploidia para o usuário final (médicos)}

A finalidade é desenvolver o protótipo de uma interface básica que possibilite aos médicos visualizar as previsões de euploidia produzidas pelo modelo. O protótipo incluirá componentes cruciais como campos de preenchimento para os dados necessários à previsão, botões de interação para envio de informações, além de uma área de apresentação dos resultados.

Para criar uma interface fácil de usar que permita aos médicos visualizar as previsões de euploidia, empregaremos o  \textbf{Figma}, um software colaborativo baseado na web para a criação de interfaces. O Figma disponibiliza funcionalidades que simplificam a criação de interfaces de usuário e experiências do usuário, priorizando a colaboração em tempo real, por meio de uma gama de ferramentas de edição vetorial e prototipagem \cite{figma2024}.

O resultado esperado é que o protótipo da interface básica possibilite aos médicos uma visualização clara e intuitiva das previsões de euploidia. A interface precisa ser funcional e esteticamente atraente, assegurando a compreensão simples dos resultados exibidos.

Complementarmente, a interface web será implementada com as seguintes tecnologias modernas:

\begin{itemize}
\item \textbf{Next.js com App Router}: Será adotado o framework Next.js com a nova arquitetura de roteamento baseada em diretórios (app/), permitindo uma organização clara entre páginas, componentes reutilizáveis (components/) e bibliotecas auxiliares (lib/). Essa estruturação favorecerá a escalabilidade e a manutenção do projeto.

\item \textbf{TypeScript}: A linguagem utilizada será TypeScript, por sua tipagem estática que proporcionará maior segurança no desenvolvimento, especialmente relevante em projetos que lidam com dados médicos sensíveis.

\item \textbf{TailwindCSS}: A estilização será feita com TailwindCSS, o que permitirá construir rapidamente uma interface responsiva e visualmente alinhada às cores definidas para o projeto (verde e azul), com consistência e flexibilidade.

\item \textbf{Vercel}: A aplicação será hospedada na plataforma Vercel, que oferece integração nativa com Next.js e permite deploys contínuos e automáticos. Isso garantirá que a versão mais recente da aplicação esteja sempre disponível online para testes e validações.

\item \textbf{Leitura de Planilhas XLSX}: A aplicação contará com uma funcionalidade de upload de arquivos .xlsx contendo os dados morfocinéticos dos embriões. Após o envio, a aplicação realizará a leitura e simulará uma resposta do modelo de aprendizado de máquina, classificando os embriões como euploides ou aneuploides.
\end{itemize}

Com essa abordagem, espera-se disponibilizar uma interface funcional que complementará o protótipo em Figma, possibilitando testes reais e coleta de feedback por parte de usuários da área médica. O foco será garantir clareza na visualização dos resultados, facilidade de navegação e estética coerente com a finalidade científica e profissional do projeto.